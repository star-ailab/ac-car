# https://github.com/spro/char-rnn.pytorch

#import unidecode
import string
import random
import time
import math
import torch
import numpy as np
import os
import array

cur_path = path = "/".join(os.path.realpath(__file__).split("/")[:-2])
print("current directory is : " + cur_path)
exe_path = cur_path + '/utils/evaded_rootkit/'
print (exe_path)

# Reading and un-unicode-encoding data
all_characters = string.printable
#print(all_characters)
n_characters = len(all_characters)

def sys_sample(ints):
    result = []
    for i in range(0, len(ints), 500):
        #result = np.array([result, bytez[i]])
        result.append(ints[i])
    return result

def read_file(filename):
    with open (filename,"rb") as f:
        bytez = f.read()
    #file_len = len(file)
    file = np.frombuffer(bytez,dtype=np.uint8)[np.newaxis,:][0]
    # all_characters = file
    # n_characters = len(all_characters)
    return file, len(file), bytez

# Turning a string into a tensor

def char_tensor(string):
    # tensor = torch.zeros(len(string)).long()
    # for c in range(len(string)):
        # try:
            # tensor[c] = string[c]
        # except:
        #     continue
    #print(torch.as_tensor(string))
    return torch.as_tensor(string)

# Readable time elapsed

def time_since(since):
    s = time.time() - since
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)

# with open ('neg/mset7tk.dll',"rb") as f:
#         file = f.read()
# file = np.frombuffer(file,dtype=np.uint8)[np.newaxis,:][0]
# print(file[0:20])

# Preprocessing: Training Corpus Construction: Do systematic sampling and concat the results to make a unified file to learn from
if __name__ == '__main__':
    exe_data = os.listdir(exe_path)
    train_corpus= []
    for file_name in exe_data:
        ints,_,_ = read_file(exe_path+file_name)
        sampled = sys_sample(ints)
        train_corpus = train_corpus + sampled
        #train_corpus.extend(sampled)
    # Write corpus
    bytez = array.array('B', train_corpus).tobytes()
    f = open("train_corpus", "wb")
    f.write(bytez)
    f.close()
